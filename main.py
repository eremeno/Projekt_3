"""
main.py: tÅ™etÃ­ projekt do Engeto Online Python Akademie
author: Oleg Eremenko
email: eremenko.oleg26@gmail.com



Skript pro staÅ¾enÃ­ a export vÃ½sledkÅ¯ voleb do PoslaneckÃ© snÄ›movny ÄŒR 2017 z portÃ¡lu volby.cz.

Na zÃ¡kladÄ› zadanÃ© URL ÃºzemnÃ­ho celku (napÅ™. okresu) stÃ¡hne pro kaÅ¾dou obec:
- kÃ³d obce
- nÃ¡zev obce
- voliÄi v seznamu
- vydanÃ© obÃ¡lky
- platnÃ© hlasy
- poÄet hlasÅ¯ pro kaÅ¾dou politickou stranu

Data jsou nÃ¡slednÄ› uloÅ¾ena do CSV souboru s odpovÃ­dajÃ­cÃ­ hlaviÄkou.

SpuÅ¡tÄ›nÃ­:
    python main.py "https://www.volby.cz/pls/ps2017nss/ps32?..." vystup_okres.csv
"""

import sys
import requests
from bs4 import BeautifulSoup
import csv
from urllib.parse import urljoin
from typing import List, Tuple

def validate_arguments(args: List[str]) -> bool:
    """
    OvÄ›Å™Ã­, zda jsou zadanÃ© argumenty sprÃ¡vnÃ©:
    - musÃ­ bÃ½t zadÃ¡ny pÅ™esnÄ› 2 argumenty (URL a vÃ½stupnÃ­ CSV soubor)
    - URL musÃ­ odkazovat na strÃ¡nku ÃºzemnÃ­ho celku na volby.cz
    - vÃ½stupnÃ­ soubor musÃ­ konÄit na .csv

    :param args: Argumenty ze sys.argv
    :return: True pokud jsou validnÃ­, jinak False
    """
    if len(args) != 3:
        print("âŒ Zadejte pÅ™esnÄ› dva argumenty: <URL> <nÃ¡zev_souboru.csv>")
        return False
    if not args[1].startswith("https://www.volby.cz/pls/ps2017nss/ps3"):
        print("âŒ PrvnÃ­ argument musÃ­ bÃ½t platnÃ½ odkaz na strÃ¡nku ÃºzemnÃ­ho celku z volby.cz.")
        return False
    if not args[2].endswith(".csv"):
        print("âŒ DruhÃ½ argument musÃ­ bÃ½t nÃ¡zev CSV souboru konÄÃ­cÃ­ na .csv")
        return False
    return True

def get_soup(url: str) -> BeautifulSoup:
    """
    NaÄte a zpracuje HTML obsah z danÃ© URL pomocÃ­ knihovny BeautifulSoup.

    :param url: URL adresa strÃ¡nky
    :return: Parsed HTML jako BeautifulSoup objekt
    """
    response = requests.get(url)
    response.raise_for_status()
    return BeautifulSoup(response.text, 'html.parser')

def get_obec_links(soup: BeautifulSoup, base_url: str) -> List[Tuple[str, str, str]]:
    """
    Najde vÅ¡echny odkazy na strÃ¡nky jednotlivÃ½ch obcÃ­ v ÃºzemnÃ­m celku.

    :param soup: HTML hlavnÃ­ strÃ¡nky ÃºzemnÃ­ho celku
    :param base_url: ZÃ¡kladnÃ­ URL pro doplnÄ›nÃ­ relativnÃ­ch odkazÅ¯
    :return: Seznam trojic (odkaz na obec, kÃ³d obce, nÃ¡zev obce)
    """
    results = []
    for row in soup.find_all('tr'):
        cislo_td = row.find('td', class_='cislo')
        name_td = row.find('td', class_='overflow_name')
        if cislo_td and name_td:
            a = cislo_td.find('a')
            if a and a.get('href'):
                full_url = urljoin(base_url, a['href'])
                code = a.text.strip()
                name = name_td.text.strip()
                results.append((full_url, code, name))
    return results

def get_party_names(soup: BeautifulSoup) -> List[str]:
    """
    ZÃ­skÃ¡ nÃ¡zvy vÅ¡ech politickÃ½ch stran z jednÃ© strÃ¡nky obce.

    :param soup: HTML strÃ¡nky jednÃ© obce
    :return: Seznam nÃ¡zvÅ¯ stran v poÅ™adÃ­, v jakÃ©m jsou uvedeny
    """
    names = []
    for table in soup.find_all('table'):
        for tr in table.find_all('tr'):
            name_td = tr.find('td', class_='overflow_name')
            if name_td:
                names.append(name_td.text.strip())
    return names

def parse_obec_data(url: str) -> List[str]:
    """
    NaÄte volebnÃ­ vÃ½sledky pro jednu obec:
    - poÄet registrovanÃ½ch voliÄÅ¯
    - poÄet vydanÃ½ch obÃ¡lek
    - poÄet platnÃ½ch hlasÅ¯
    - poÄet platnÃ½ch hlasÅ¯ pro kaÅ¾dou politickou stranu

    :param url: URL strÃ¡nky konkrÃ©tnÃ­ obce
    :return: Seznam hodnot v poÅ™adÃ­: [voliÄi, obÃ¡lky, platnÃ©, hlasy pro strany...]
    """
    soup = get_soup(url)

    volici = soup.find('td', headers="sa2").text.strip().replace('\xa0', '')
    obalky = soup.find('td', headers="sa3").text.strip().replace('\xa0', '')
    platne = soup.find('td', headers="sa6").text.strip().replace('\xa0', '')

    hlasy = []

    for table in soup.find_all('table'):
        for tr in table.find_all('tr'):
            name_td = tr.find('td', class_='overflow_name')
            if not name_td:
                continue

            vote_td = None
            for td in tr.find_all('td', class_='cislo'):
                headers = td.get('headers', '')
                if isinstance(headers, str):
                    headers = headers.split()
                if any(h.endswith('sa2') for h in headers):
                    vote_td = td
                    break

            if vote_td:
                vote = vote_td.text.strip().replace('\xa0', '')
                hlasy.append(vote)
            else:
                hlasy.append('') 

    return [volici, obalky, platne] + hlasy

def save_to_csv(filename: str, header: List[str], data: List[List[str]]) -> None:
    """
    UloÅ¾Ã­ vÃ½sledky do CSV souboru.

    :param filename: NÃ¡zev vÃ½stupnÃ­ho souboru
    :param header: HlaviÄka CSV souboru (seznam nÃ¡zvÅ¯ sloupcÅ¯)
    :param data: VlastnÃ­ datovÃ¡ ÄÃ¡st CSV (seznam Å™Ã¡dkÅ¯)
    """
    with open(filename, mode='w', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        writer.writerow(header)
        writer.writerows(data)

def main():
    """
    HlavnÃ­ Å™Ã­dicÃ­ funkce skriptu.
    - Zpracuje argumenty
    - NaÄte seznam obcÃ­
    - ZÃ­skÃ¡ nÃ¡zvy stran z prvnÃ­ obce
    - ZÃ­skÃ¡ a zpracuje data pro kaÅ¾dou obec
    - VÃ½sledky uloÅ¾Ã­ do CSV
    """
    if not validate_arguments(sys.argv):
        return

    url = sys.argv[1]
    output_file = sys.argv[2]

    print("ğŸ”„ NaÄÃ­tÃ¡m hlavnÃ­ strÃ¡nku...")
    main_soup = get_soup(url)
    obec_infos = get_obec_links(main_soup, url)

    if not obec_infos:
        print("âŒ Å½Ã¡dnÃ© obce nebyly nalezeny.")
        return

    print("ğŸ“‹ NaÄÃ­tÃ¡m nÃ¡zvy stran z prvnÃ­ obce...")
    first_obec_soup = get_soup(obec_infos[0][0])
    party_names = get_party_names(first_obec_soup)
    header = ["code", "location", "registered", "envelopes", "valid"] + party_names

    data = []
    for i, (link, code, name) in enumerate(obec_infos, 1):
        print(f"ğŸ“¥ {i}/{len(obec_infos)} ZpracovÃ¡vÃ¡m: {name}")
        row = parse_obec_data(link)
        full_row = [code, name] + row
        data.append(full_row)

    save_to_csv(output_file, header, data)
    print(f"âœ… Hotovo! VÃ½sledky byly uloÅ¾eny do souboru: {output_file}")

if __name__ == "__main__":
    main()
